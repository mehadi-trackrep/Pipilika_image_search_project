import scrapy
from ecommerce import items
import datetime

# from scrapy.spiders import CrawlSpider, Rule
# from scrapy.linkextractors import LinkExtractor
# from scrapy.spidermiddlewares.httperror import HttpError
# from twisted.internet.error import DNSLookupError
# from twisted.internet.error import TimeoutError

class DarazSpider(scrapy.Spider):

    name = "daraz"
    #allowed_domains = ["daraz.com.bd"]

    start_urls = [
        'https://www.daraz.com.bd/'
        #'https://www.daraz.com.bd/mens-western-clothing/'
    ]

    def start_requests(self):

        for url in self.start_urls:

            request = scrapy.Request(url=url, callback=self.parse_category)
            #request = scrapy.Request(url=url, callback=self.parse_product_list)
            request.meta['depth'] = 1
            yield request

    def parse_category(self, response):

        category_tags = response.selector.xpath('//nav[@id="menuFixed"]//div[@class="categories"]/a[@class="category"]/@href').extract()

        for tag in category_tags:
            request = scrapy.Request(url=tag, callback=self.parse_product_list)
            request.meta['depth'] = response.meta['depth'] + 1
            yield request

    def parse_product_list(self, response):

        #category = response.meta['category']
        product_list_urls = response.selector.xpath('//div[@class="sku -gallery -validate-size "]/a[@class="link"]/@href').extract()

        for url in product_list_urls:
            #print '==========================>2222222222222222222222222222222222222222222222222 '
            request = scrapy.Request(url=url, callback=self.parse_product_detail)
            category_name=response.selector.xpath('//h1[@class="title"]/text()').extract()
            request.meta['category'] = category_name
            #print category_name
            #print request.meta['category']
            request.meta['depth'] = response.meta['depth'] + 1
            yield request
        print '==========================>nnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnn=> '
        next_page = response.selector.xpath('//li[@class="item"]/a[@title="Next"]/@href').extract_first()
        if next_page is not None:
            yield response.follow(next_page, callback=self.parse_product_list)
           

    def parse_product_detail(self, response):

        product = items.Ecommerce_product_items()
        product['url'] = response.url
        #print 'rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr'
        #print response.url
        product['title'] = response.selector.xpath('//div[@class="details -validate-size"]/span/h1[@class="title"]/ text()').extract()
        product['categories'] =response.meta['category']
        #print 'cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc'
        #print response.meta['category']
        #product['currency'] = response.xpath('//div[@class="price-box"]//span//@data-currency-iso').extract()[0]
        product['currency'] ='BDT'
        
        product['price'] =  response.selector.xpath('//span[@dir="ltr"]/text()').extract()
        product['images'] = response.selector.xpath(u'//div[@class="product-preview"]/img/@data-zoom').extract()
        product['last_updated'] = datetime.datetime.now()

        # print 'product details function -------------------------------------------------> '
        # print product['url']
        # print product['title']
        # print product['categories']
        # print product['currency']
        # print product['price']
        # print product['images']
        # print product['last_updated']

        yield product

